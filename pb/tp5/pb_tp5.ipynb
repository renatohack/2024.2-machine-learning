{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0009fb64-6b07-4d8f-9238-a9c020422702",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08097f5b-0b1b-426b-9178-383c73f944a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.13.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: pyLDAvis in /opt/conda/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (1.13.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (2.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (1.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (3.1.3)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (2.9.0)\n",
      "Requirement already satisfied: funcy in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (1.4.2)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (4.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from pyLDAvis) (69.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.4.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim->pyLDAvis) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->pyLDAvis) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "!pip install --upgrade gensim\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5961b6ca-ca0c-4a4b-9f0b-65a22a45e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad1d1c3-1f89-4ac4-90b2-13ca50ae4e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602587f5-c758-4e19-93f8-739b10d929ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programa treinamento jornalismo agroindústr su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofício enviar juiz sergio morar em este sexta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex governador rio sérgio cabral transferir com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aplauso vaia juiz federal sergio Moro responsá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex Executivo empreiteira odebrecht afirmar aco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  programa treinamento jornalismo agroindústr su...\n",
       "1  ofício enviar juiz sergio morar em este sexta ...\n",
       "2  ex governador rio sérgio cabral transferir com...\n",
       "3  aplauso vaia juiz federal sergio Moro responsá...\n",
       "4  ex Executivo empreiteira odebrecht afirmar aco..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('df.p', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570afa59-6e7e-4b1f-81f6-45837f1b2419",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a451e2c2-ff72-41e8-bb40-7b5246be0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    min_df=10,\n",
    "    max_features=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e994ff8d-6e0e-4762-aac5-b97f3186aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c99bdc-e197-437a-82b5-0ee88a0589d6",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818b8e08-0d9b-41cc-8f68-ff47243417dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [word_tokenize(doc.lower(), language=\"portuguese\") for doc in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af88a93-96e5-47cd-85c0-9e5249473fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11cd83e-e9ff-47d7-910c-5443aca8ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, texts, limit, start=2, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1113d3e2-4070-4729-a6d6-ba175753a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 5\n",
    "model_list, coherence_values = compute_coherence_values(corpus=corpus, dictionary=dictionary, texts=tokenized_docs, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e7bb45-19ec-49ed-9741-8f4a4365a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor número de tópicos: 2\n"
     ]
    }
   ],
   "source": [
    "optimal_model_index = coherence_values.index(max(coherence_values))\n",
    "optimal_model = model_list[optimal_model_index]\n",
    "optimal_num_topics = optimal_model.num_topics\n",
    "\n",
    "print(f\"Melhor número de tópicos: {optimal_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5d1c9bf-1dbf-417c-80c8-f7bce33f5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_topic(lda_model, corpus):\n",
    "    document_topics = []\n",
    "    for bow in corpus:\n",
    "        topic_probs = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "        dominant_topic = max(topic_probs, key=lambda x: x[1])[0]\n",
    "        document_topics.append(dominant_topic)\n",
    "    return document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3ac446-b07e-46b2-aad9-2fac8ec2069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = get_document_topic(optimal_model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee467dc-bccb-4551-9601-65433c35d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programa treinamento jornalismo agroindústr su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofício enviar juiz sergio morar em este sexta ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex governador rio sérgio cabral transferir com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aplauso vaia juiz federal sergio Moro responsá...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex Executivo empreiteira odebrecht afirmar aco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc  topic\n",
       "0  programa treinamento jornalismo agroindústr su...      1\n",
       "1  ofício enviar juiz sergio morar em este sexta ...      0\n",
       "2  ex governador rio sérgio cabral transferir com...      0\n",
       "3  aplauso vaia juiz federal sergio Moro responsá...      0\n",
       "4  ex Executivo empreiteira odebrecht afirmar aco...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'doc': df['text'], 'topic': document_topics})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9650ed69-dea4-4f25-9268-fab51f8124ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0: dizer poder fazer ano dia\n",
      "Tópico 1: ano poder dizer grande em\n"
     ]
    }
   ],
   "source": [
    "def get_topic_words(lda_model, num_words=5):\n",
    "    topic_words = {}\n",
    "    for i, topic in enumerate(lda_model.show_topics(formatted=False, num_words=num_words)):\n",
    "        topic_words[i] = [word for word, _ in topic[1]]\n",
    "    return topic_words\n",
    "\n",
    "# Obter as palavras representativas para cada tópico\n",
    "topic_words = get_topic_words(optimal_model, num_words=5)\n",
    "\n",
    "# Exibir os tópicos e suas palavras mais importantes\n",
    "for topic, words in topic_words.items():\n",
    "    print(f\"Tópico {topic}: {' '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9fe3b-e5fd-4271-97c0-25ff043f13fb",
   "metadata": {},
   "source": [
    "# LDA visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e230d589-2703-45fc-aaa6-c9e55daa684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pyLDAvis.lda_model.prepare(lda_model, dtm, vectorizer, **kwargs)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.lda_model.prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed440640-92c0-48d2-9a55-ab215e0b471d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'getA1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75523/1682006411.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tsne'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyLDAvis/lda_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyLDAvis/lda_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdoc_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_doc_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mterm_freqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_term_freqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtopic_term_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_topic_term_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     err_msg = ('Topic-term distributions and document-term matrix'\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyLDAvis/lda_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dtm)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_doc_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetA1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'getA1'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.lda_model.prepare(optimal_model, tfidf_matrix, tfidf_vectorizer, sort_topics=False, mds='tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
