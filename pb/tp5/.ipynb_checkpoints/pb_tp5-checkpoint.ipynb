{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0009fb64-6b07-4d8f-9238-a9c020422702",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08097f5b-0b1b-426b-9178-383c73f944a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.13.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5961b6ca-ca0c-4a4b-9f0b-65a22a45e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aad1d1c3-1f89-4ac4-90b2-13ca50ae4e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "602587f5-c758-4e19-93f8-739b10d929ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programa treinamento jornalismo agroindústr su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ofício enviar juiz sergio morar em este sexta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ex governador rio sérgio cabral transferir com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aplauso vaia juiz federal sergio Moro responsá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ex Executivo empreiteira odebrecht afirmar aco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  programa treinamento jornalismo agroindústr su...\n",
       "1  ofício enviar juiz sergio morar em este sexta ...\n",
       "2  ex governador rio sérgio cabral transferir com...\n",
       "3  aplauso vaia juiz federal sergio Moro responsá...\n",
       "4  ex Executivo empreiteira odebrecht afirmar aco..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('df.p', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570afa59-6e7e-4b1f-81f6-45837f1b2419",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a451e2c2-ff72-41e8-bb40-7b5246be0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    min_df=10,\n",
    "    max_features=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e994ff8d-6e0e-4762-aac5-b97f3186aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c99bdc-e197-437a-82b5-0ee88a0589d6",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "818b8e08-0d9b-41cc-8f68-ff47243417dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [word_tokenize(doc.lower(), language=\"portuguese\") for doc in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae1e7a63-5605-462e-8f93-907634566b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1075a0a1-c63d-404b-a3f2-213529519368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44522760-983a-458e-a1a0-799d5ea82305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_score(num_topics):\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    return coherence_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "247e5a2e-c1e6-4278-95c5-3bc723762039",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_numbers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m coherence_scores \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_coherence_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtopic_numbers\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_numbers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m coherence_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_coherence_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m topic_numbers]\n",
      "Cell \u001b[0;32mIn[52], line 4\u001b[0m, in \u001b[0;36mcompute_coherence_score\u001b[0;34m(num_topics)\u001b[0m\n\u001b[1;32m      2\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(corpus, num_topics\u001b[38;5;241m=\u001b[39mnum_topics, id2word\u001b[38;5;241m=\u001b[39mdictionary, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m      3\u001b[0m coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39mtexts, dictionary\u001b[38;5;241m=\u001b[39mdictionary, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m coherence_lda \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_model_lda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coherence_lda\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/models/coherencemodel.py:614\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    606\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m     confirmed_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_measures(confirmed_measures)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/models/coherencemodel.py:574\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    572\u001b[0m     segmented_topics \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mseg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_topics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(with_std\u001b[38;5;241m=\u001b[39mwith_std, with_support\u001b[38;5;241m=\u001b[39mwith_support)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;129;01min\u001b[39;00m BOOLEAN_DOCUMENT_BASED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/models/coherencemodel.py:546\u001b[0m, in \u001b[0;36mCoherenceModel.estimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    544\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyed_vectors\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/topic_coherence/probability_estimation.py:156\u001b[0m, in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m     accumulator \u001b[38;5;241m=\u001b[39m ParallelWordOccurrenceAccumulator(processes, top_ids, dictionary)\n\u001b[1;32m    155\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to estimate probabilities from sliding windows\u001b[39m\u001b[38;5;124m\"\u001b[39m, accumulator)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/topic_coherence/text_analysis.py:445\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.accumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    442\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats accumulation interrupted; <= \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m documents processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_docs)\n\u001b[1;32m    443\u001b[0m     interrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_accumulators(accumulators)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/gensim/topic_coherence/text_analysis.py:522\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.terminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    520\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accumulators) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(workers):\n\u001b[0;32m--> 522\u001b[0m     accumulators\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    523\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m accumulators retrieved from output queue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(accumulators))\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m workers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "topic_numbers = range(8, 11)\n",
    "coherence_scores = [compute_coherence_score(num) for num in topic_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ef22c-e35f-4b70-99f9-e5210a2da084",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(topic_numbers, coherence_scores)\n",
    "plt.xlabel('Número de Tópicos')\n",
    "plt.ylabel('Pontuação de Coerência')\n",
    "plt.title('Coerência vs Número de Tópicos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5f6e6-971f-461b-b1a1-86e0cf777a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_topics = topic_numbers[coherence_scores.index(max(coherence_scores))]\n",
    "best_num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af88a93-96e5-47cd-85c0-9e5249473fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
